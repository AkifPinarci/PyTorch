{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"Helpers\")\n",
    "sys.path.append(path)\n",
    "from helper_functions import plot_predictions, plot_decision_boundary, accuracy_fn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\", \n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\", \n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "# image, label = train_data[0]\n",
    "# print(image, label)\n",
    "# print(train_data.classes)\n",
    "# print(train_data.class_to_idx)   \n",
    "# print(train_data.targets)\n",
    "# print(image.shape)\n",
    "# print(train_data.classes[label])\n",
    "\n",
    "# plt.imshow(image.squeeze(), cmap = \"gray\")\n",
    "# plt.title(train_data.classes[label])\n",
    "# plt.axis(False)\n",
    "# plt.show()\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# fig = plt.figure(figsize = (9, 9))\n",
    "# rows, cols, = 4, 4\n",
    "# for i in range(1, rows * cols + 1):\n",
    "#     random_index = torch.randint(0, len(train_data), size = [1]).item()\n",
    "#     img, label = train_data[random_index]\n",
    "#     fig.add_subplot(rows, cols, i)\n",
    "#     plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "#     plt.title(train_data.classes[label])\n",
    "#     plt.axis(False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_data,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size= BATCH_SIZE,\n",
    "                             shuffle= False)\n",
    "\n",
    "# print(f\"Lenth of the train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "# print(f\"Lenth of the test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# train_features_batch, train_label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "# img, label = train_features_batch[idx], train_label_batch[idx]\n",
    "# print(f\"Image Size: {img.shape} Label: {label} LabelSize = {label.shape}\")\n",
    "# plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "# plt.title(train_data.classes[label])\n",
    "# plt.axis(False)\n",
    "# plt.show()\n",
    "\n",
    "# # Create a flatten layer\n",
    "# flatten_model = nn.Flatten()\n",
    "\n",
    "# # Get a single sample\n",
    "# x = train_features_batch[0]\n",
    "\n",
    "# # Flatten the sample\n",
    "# output = flatten_model(x)\n",
    "# print(x.shape)\n",
    "# print(output.shape)\n",
    "\n",
    "# # Build a baseline model\n",
    "\n",
    "# dummy_x = torch.rand([1, 28, 28])\n",
    "# print(model_0(dummy_x).shape)\n",
    "\n",
    "# Setup loss, optimizer and evaluation metrics\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr= 0.1)\n",
    "\n",
    "def print_train_time(start, end, device=torch.device):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.2f} seconds\")\n",
    "    return  total_time\n",
    "# start_time = timer()\n",
    "# end_time = timer()\n",
    "# print(print_train_time(start_time, end_time))\n",
    "\n",
    "# 1. Loop through epochs.\n",
    "# 2. Loop through training batches, perform training steps, calculate the train loss per batch.\n",
    "# 3. Loop through testing batches, perform testing steps, calculate the test loss per batch.\n",
    "# 4. Print out what's happening.\n",
    "# 5. Time it all (for fun).\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# train_time_start_on_cpu = timer()\n",
    "# epochs = 3\n",
    "\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#     print(f\"Epoch: {epoch}\\n\")\n",
    "#     # Training\n",
    "#     train_loss = 0\n",
    "#     # Add a loop to loop through the training batches\n",
    "#     for batch, (X, y) in enumerate(train_dataloader):\n",
    "#         X.to(device)\n",
    "#         y.to(device)\n",
    "#         model_0.train()\n",
    "#         # Forward pass\n",
    "#         y_pred = model_0(X)\n",
    "\n",
    "#         # Calculate loss\n",
    "#         loss = loss_fn(y_pred, y)\n",
    "#         train_loss += loss # Acccumulate train loss\n",
    "\n",
    "#         # Optimizer zero grad\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Back propagation\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Optimizer step\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch % 400 == 0:\n",
    "#             print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "#     # Divide total train loss by length of train dataloader\n",
    "#     train_loss /= len(train_dataloader)\n",
    "\n",
    "#     ### Testing\n",
    "#     test_loss, test_acc = 0, 0\n",
    "#     model_0.eval()\n",
    "#     with torch.inference_mode():\n",
    "#         for X, y in test_dataloader:\n",
    "#             test_pred = model_0(X)\n",
    "#             test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "#             test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1)) \n",
    "#         test_loss /= len(test_dataloader)\n",
    "#         test_acc /= len(test_dataloader)\n",
    "\n",
    "#     print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "# train_time_end_on_cpu = timer()\n",
    "# total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "#                                            end=train_time_end_on_cpu,\n",
    "#                                            device=str(next(model_0.parameters()).device))\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, accuracy_fn, device):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make Predictions\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y, y_pred.argmax(dim = 1))\n",
    "        # Scale the loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "        return {\n",
    "            \"model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc\n",
    "        }\n",
    "    \n",
    "# model_0_result = eval_model(model_0, test_dataloader, loss_fn, accuracy_fn, \"cpu\")\n",
    "# print(model_0_result)\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, inf, outf, hidden):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=inf, out_features=hidden),\n",
    "            nn.Linear(in_features=hidden, out_features=outf)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.layer_stack(data)\n",
    "\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, inf, outf, hidden):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=inf, out_features=hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden, out_features=outf),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.layer_stack(data)\n",
    "    \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, hidden_units):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(  \n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.cnn_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(  \n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=output_shape,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=490, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.cnn_block_1(data)\n",
    "        # print(f\"Data shape after CONV block 1: {data.shape}\")\n",
    "        data = self.cnn_block_2(data)\n",
    "        # print(f\"Data shape after CONV block 2: {data.shape}\")\n",
    "        data = self.classifier(data)\n",
    "        # print(f\"Data shape after classifier: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, accuracy_fn, device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Put data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_loss += loss # Acccumulate train loss\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim = 1))\n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.5f}\")\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1)) \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "def train_loop(epochs, model, train_dataloader, test_dataloader, optimizer, loss_fn, accuracy_fn, device):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"\\nEpoch: {epoch}\\n\")\n",
    "        train_step(model, train_dataloader, loss_fn, optimizer, accuracy_fn, device)\n",
    "        test_step(model, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "\n",
    "# torch.cuda.manual_seed(42) \n",
    "# torch.manual_seed(42)\n",
    "# model_0 = FashionMNISTModelV0(784, 10, len(train_data.classes)).to(device)\n",
    "\n",
    "# torch.cuda.manual_seed(42)\n",
    "# torch.manual_seed(42)   \n",
    "# model_1 = FashionMNISTModelV1(784, 10, len(train_data.classes)).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train_loop(\n",
    "#     epochs = 3, \n",
    "#     model = model_0, \n",
    "#     train_dataloader = train_dataloader, \n",
    "#     test_dataloader = test_dataloader, \n",
    "#     optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.1), \n",
    "#     loss_fn = loss_fn, \n",
    "#     accuracy_fn = accuracy_fn,  \n",
    "#     device = device\n",
    "#     )\n",
    "\n",
    "# train_loop(\n",
    "#     epochs = 3, \n",
    "#     model = model_1, \n",
    "#     train_dataloader = train_dataloader, \n",
    "#     test_dataloader = test_dataloader, \n",
    "#     optimizer = torch.optim.SGD(params=model_1.parameters(), lr = 0.1), \n",
    "#     loss_fn = loss_fn, \n",
    "#     accuracy_fn = accuracy_fn,  \n",
    "#     device = device\n",
    "#     )\n",
    "\n",
    "# model_0_results = eval_model(model_0, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "# model_1_results = eval_model(model_1, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "# print(model_0_results)\n",
    "# print(model_1_results)\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# images = torch.randn(size = (32, 1, 2, 2))\n",
    "# test_image = images[0]\n",
    "\n",
    "# conv_layer = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride = 2, padding = 0)\n",
    "# max_pool_layer = nn.MaxPool2d(kernel_size = 2)\n",
    "# # res = conv_layer(test_image)\n",
    "# res = max_pool_layer(test_image)\n",
    "# # print(test_image.shape)\n",
    "# print(test_image)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# plt.imshow(test_image.squeeze(), cmap=\"gray\")\n",
    "# plt.show()\n",
    "# image, label = train_data[0]\n",
    "# print(image.shape)\n",
    "# res = model_2(image.unsqueeze(dim = 1).to(device))\n",
    "# print(res)\n",
    "# # plt.imshow(res.squeeze(), cmap=\"gray\")\n",
    "# # plt.show()\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, hidden_units=10, output_shape = 10).to(device)\n",
    "\n",
    "start_time_conv = timer()\n",
    "train_loop(\n",
    "    epochs = 0, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "end_time_conv = timer()\n",
    "total_time_model2 = print_train_time(start_time_conv, end_time_conv, device)\n",
    "\n",
    "model_2_results = eval_model(\n",
    "    model = model_2,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(42) \n",
    "torch.manual_seed(42)\n",
    "model_0 = FashionMNISTModelV0(784, 10, len(train_data.classes)).to(device)\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)   \n",
    "model_1 = FashionMNISTModelV1(784, 10, len(train_data.classes)).to(device)\n",
    "start_time_model0 = timer()\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_0, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "end_time_model0 = timer()\n",
    "total_time_model0 = print_train_time(start_time_model0, end_time_model0)\n",
    "start_time_model1 = timer()\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_1, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_1.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "end_time_model1 = timer()\n",
    "total_time_model1 = print_train_time(start_time_model1, end_time_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results = eval_model(\n",
    "    model = model_0,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")\n",
    "model_1_results = eval_model(\n",
    "    model = model_1,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")\n",
    "print(model_0_results)\n",
    "print(model_1_results)\n",
    "print(model_2_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(\n",
    "    epochs = 5, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_conv = timer()\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "end_time_conv = timer()\n",
    "total_time_model2 = print_train_time(start_time_conv, end_time_conv, device)\n",
    "\n",
    "model_2_results = eval_model(\n",
    "    model = model_2,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "compare_results[\"trainin_time\"] = [total_time_model0, total_time_model1, total_time_model2]\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our model results\n",
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"accuracy (%)\")\n",
    "plt.ylabel(\"model_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and evaluate random predictions with best model\n",
    "\n",
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logit)\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0) # note: perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have a batch size of 1, so can perform on dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "            \n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fig = plt.figure(figsize = (9, 9))\n",
    "# rows, cols, = 4, 4\n",
    "# for i in range(1, rows * cols + 1):\n",
    "#     random_index = torch.randint(0, len(train_data), size = [1]).item()\n",
    "#     img, label = train_data[random_index]\n",
    "#     fig.add_subplot(rows, cols, i)\n",
    "#     plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "#     plt.title(train_data.classes[label])\n",
    "#     plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.001), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "img, label = test_data[0]\n",
    "for img, label in test_data:\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label)\n",
    "# plt.imshow(test_samples[1].squeeze(), cmap = \"gray\")\n",
    "# plt.title(test_data.classes[test_labels[1]])\n",
    "# plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs= make_predictions(model=model_2, \n",
    "                             data=test_images)\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img, label = test_data[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "rows = 3\n",
    "cols = 3\n",
    "track = 0\n",
    "for i, img in enumerate(test_images):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "    pred_label = classes[pred_classes[i]]\n",
    "    truth_label = classes[test_labels[i]]\n",
    "    title_text = f\"Pred: {pred_label}-Truth: {truth_label}\"\n",
    "    if truth_label == pred_label:\n",
    "        plt.title(title_text, c = \"g\", fontsize = 10)\n",
    "    else:\n",
    "        plt.title(title_text, c = \"r\", fontsize = 10)\n",
    "    plt.axis(False)\n",
    "    track += 1\n",
    "    if track == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "rows = 3\n",
    "cols = 3\n",
    "track = 0\n",
    "skip = 0\n",
    "for i, img in enumerate(test_images):\n",
    "    pred_label = classes[pred_classes[i]]\n",
    "    truth_label = classes[test_labels[i]]\n",
    "    if truth_label != pred_label and skip % 7 == 0:\n",
    "        plt.subplot(rows, cols, track + 1)\n",
    "        plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "        \n",
    "        title_text = f\"Pred: {pred_label}-Truth: {truth_label}\"\n",
    "        plt.title(title_text, c = \"r\", fontsize = 10)\n",
    "        plt.axis(False)\n",
    "        track += 1\n",
    "        if track == 9:\n",
    "            break\n",
    "    skip += 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "10 Making a confusion matrix for further prediction evaluation\n",
    "\n",
    "1. Make predictions with out trained model on the test dataset\n",
    "2. Make a confusion matrix 'torchmetrics.ConfusionMatrix'\n",
    "3. Plot the confusion matrix using 'mlxtend.plotting.plot_confusion_matrix()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend, torchmetrics\n",
    "print(mlxtend.__version__)\n",
    "print(torchmetrics.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making Predictions...\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_logits = model_2(X\n",
    "                           )\n",
    "        y_pred = torch.softmax(y_logits.squeeze(), dim = 0).argmax(dim = 1)\n",
    "        y_preds.append(y_pred.cpu())\n",
    "\n",
    "y_pred_tensor = torch.cat(y_preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
