{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 12277507.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 1475575.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4422102/4422102 [00:00<00:00, 10447803.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5145919.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "\n",
      "Train Loss: 0.57807 | Train Acc: 79.14333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:09<00:18,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.39107 | Test accuracy: 85.41%\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Train Loss: 0.35546 | Train Acc: 87.20667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:18<00:08,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.37256 | Test accuracy: 85.93%\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Train Loss: 0.31706 | Train Acc: 88.53333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:27<00:00,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33428 | Test accuracy: 87.75%\n",
      "\n",
      "Train time on cuda: 27.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"Helpers\")\n",
    "sys.path.append(path)\n",
    "from helper_functions import plot_predictions, plot_decision_boundary, accuracy_fn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\", \n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\", \n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "# image, label = train_data[0]\n",
    "# print(image, label)\n",
    "# print(train_data.classes)\n",
    "# print(train_data.class_to_idx)   \n",
    "# print(train_data.targets)\n",
    "# print(image.shape)\n",
    "# print(train_data.classes[label])\n",
    "\n",
    "# plt.imshow(image.squeeze(), cmap = \"gray\")\n",
    "# plt.title(train_data.classes[label])\n",
    "# plt.axis(False)\n",
    "# plt.show()\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# fig = plt.figure(figsize = (9, 9))\n",
    "# rows, cols, = 4, 4\n",
    "# for i in range(1, rows * cols + 1):\n",
    "#     random_index = torch.randint(0, len(train_data), size = [1]).item()\n",
    "#     img, label = train_data[random_index]\n",
    "#     fig.add_subplot(rows, cols, i)\n",
    "#     plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "#     plt.title(train_data.classes[label])\n",
    "#     plt.axis(False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_data,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size= BATCH_SIZE,\n",
    "                             shuffle= False)\n",
    "\n",
    "# print(f\"Lenth of the train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "# print(f\"Lenth of the test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# train_features_batch, train_label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "# img, label = train_features_batch[idx], train_label_batch[idx]\n",
    "# print(f\"Image Size: {img.shape} Label: {label} LabelSize = {label.shape}\")\n",
    "# plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "# plt.title(train_data.classes[label])\n",
    "# plt.axis(False)\n",
    "# plt.show()\n",
    "\n",
    "# # Create a flatten layer\n",
    "# flatten_model = nn.Flatten()\n",
    "\n",
    "# # Get a single sample\n",
    "# x = train_features_batch[0]\n",
    "\n",
    "# # Flatten the sample\n",
    "# output = flatten_model(x)\n",
    "# print(x.shape)\n",
    "# print(output.shape)\n",
    "\n",
    "# # Build a baseline model\n",
    "\n",
    "# dummy_x = torch.rand([1, 28, 28])\n",
    "# print(model_0(dummy_x).shape)\n",
    "\n",
    "# Setup loss, optimizer and evaluation metrics\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(params=model_0.parameters(), lr= 0.1)\n",
    "\n",
    "def print_train_time(start, end, device=torch.device):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.2f} seconds\")\n",
    "    return  total_time\n",
    "# start_time = timer()\n",
    "# end_time = timer()\n",
    "# print(print_train_time(start_time, end_time))\n",
    "\n",
    "# 1. Loop through epochs.\n",
    "# 2. Loop through training batches, perform training steps, calculate the train loss per batch.\n",
    "# 3. Loop through testing batches, perform testing steps, calculate the test loss per batch.\n",
    "# 4. Print out what's happening.\n",
    "# 5. Time it all (for fun).\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# train_time_start_on_cpu = timer()\n",
    "# epochs = 3\n",
    "\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#     print(f\"Epoch: {epoch}\\n\")\n",
    "#     # Training\n",
    "#     train_loss = 0\n",
    "#     # Add a loop to loop through the training batches\n",
    "#     for batch, (X, y) in enumerate(train_dataloader):\n",
    "#         X.to(device)\n",
    "#         y.to(device)\n",
    "#         model_0.train()\n",
    "#         # Forward pass\n",
    "#         y_pred = model_0(X)\n",
    "\n",
    "#         # Calculate loss\n",
    "#         loss = loss_fn(y_pred, y)\n",
    "#         train_loss += loss # Acccumulate train loss\n",
    "\n",
    "#         # Optimizer zero grad\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Back propagation\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Optimizer step\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch % 400 == 0:\n",
    "#             print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "#     # Divide total train loss by length of train dataloader\n",
    "#     train_loss /= len(train_dataloader)\n",
    "\n",
    "#     ### Testing\n",
    "#     test_loss, test_acc = 0, 0\n",
    "#     model_0.eval()\n",
    "#     with torch.inference_mode():\n",
    "#         for X, y in test_dataloader:\n",
    "#             test_pred = model_0(X)\n",
    "#             test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "#             test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1)) \n",
    "#         test_loss /= len(test_dataloader)\n",
    "#         test_acc /= len(test_dataloader)\n",
    "\n",
    "#     print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "# train_time_end_on_cpu = timer()\n",
    "# total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "#                                            end=train_time_end_on_cpu,\n",
    "#                                            device=str(next(model_0.parameters()).device))\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, accuracy_fn, device):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make Predictions\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y, y_pred.argmax(dim = 1))\n",
    "        # Scale the loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "        return {\n",
    "            \"model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc\n",
    "        }\n",
    "    \n",
    "# model_0_result = eval_model(model_0, test_dataloader, loss_fn, accuracy_fn, \"cpu\")\n",
    "# print(model_0_result)\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, inf, outf, hidden):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=inf, out_features=hidden),\n",
    "            nn.Linear(in_features=hidden, out_features=outf)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.layer_stack(data)\n",
    "\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, inf, outf, hidden):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_features=inf, out_features=hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden, out_features=outf),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.layer_stack(data)\n",
    "    \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, hidden_units):\n",
    "        super().__init__()\n",
    "        self.cnn_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(  \n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.cnn_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(  \n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=output_shape,\n",
    "                kernel_size=3,  #\n",
    "                stride = 1,     #\n",
    "                padding = 1     # padding\n",
    "                    ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 7 * 7, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.cnn_block_1(data)\n",
    "        # print(f\"Data shape after CONV block 1: {data.shape}\")\n",
    "        data = self.cnn_block_2(data)\n",
    "        # print(f\"Data shape after CONV block 2: {data.shape}\")\n",
    "        data = self.classifier(data)\n",
    "        # print(f\"Data shape after classifier: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, accuracy_fn, device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Put data on target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_loss += loss # Acccumulate train loss\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim = 1))\n",
    "        # Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.5f}\")\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1)) \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "def train_loop(epochs, model, train_dataloader, test_dataloader, optimizer, loss_fn, accuracy_fn, device):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"\\nEpoch: {epoch}\\n\")\n",
    "        train_step(model, train_dataloader, loss_fn, optimizer, accuracy_fn, device)\n",
    "        test_step(model, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "\n",
    "# torch.cuda.manual_seed(42) \n",
    "# torch.manual_seed(42)\n",
    "# model_0 = FashionMNISTModelV0(784, 10, len(train_data.classes)).to(device)\n",
    "\n",
    "# torch.cuda.manual_seed(42)\n",
    "# torch.manual_seed(42)   \n",
    "# model_1 = FashionMNISTModelV1(784, 10, len(train_data.classes)).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# train_loop(\n",
    "#     epochs = 3, \n",
    "#     model = model_0, \n",
    "#     train_dataloader = train_dataloader, \n",
    "#     test_dataloader = test_dataloader, \n",
    "#     optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.1), \n",
    "#     loss_fn = loss_fn, \n",
    "#     accuracy_fn = accuracy_fn,  \n",
    "#     device = device\n",
    "#     )\n",
    "\n",
    "# train_loop(\n",
    "#     epochs = 3, \n",
    "#     model = model_1, \n",
    "#     train_dataloader = train_dataloader, \n",
    "#     test_dataloader = test_dataloader, \n",
    "#     optimizer = torch.optim.SGD(params=model_1.parameters(), lr = 0.1), \n",
    "#     loss_fn = loss_fn, \n",
    "#     accuracy_fn = accuracy_fn,  \n",
    "#     device = device\n",
    "#     )\n",
    "\n",
    "# model_0_results = eval_model(model_0, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "# model_1_results = eval_model(model_1, test_dataloader, loss_fn, accuracy_fn, device)\n",
    "# print(model_0_results)\n",
    "# print(model_1_results)\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# images = torch.randn(size = (32, 1, 2, 2))\n",
    "# test_image = images[0]\n",
    "\n",
    "# conv_layer = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride = 2, padding = 0)\n",
    "# max_pool_layer = nn.MaxPool2d(kernel_size = 2)\n",
    "# # res = conv_layer(test_image)\n",
    "# res = max_pool_layer(test_image)\n",
    "# # print(test_image.shape)\n",
    "# print(test_image)\n",
    "# print(res.shape)\n",
    "# print(res)\n",
    "# plt.imshow(test_image.squeeze(), cmap=\"gray\")\n",
    "# plt.show()\n",
    "# image, label = train_data[0]\n",
    "# print(image.shape)\n",
    "# res = model_2(image.unsqueeze(dim = 1).to(device))\n",
    "# print(res)\n",
    "# # plt.imshow(res.squeeze(), cmap=\"gray\")\n",
    "# # plt.show()\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, hidden_units=10, output_shape = 10).to(device)\n",
    "\n",
    "start_time_conv = timer()\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "end_time_conv = timer()\n",
    "print_train_time(start_time_conv, end_time_conv, device)\n",
    "\n",
    "model_2_results = eval_model(\n",
    "    model = model_2,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "\n",
      "Train Loss: 0.58804 | Train Acc: 79.18667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:16,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.52466 | Test accuracy: 81.48%\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Train Loss: 0.47645 | Train Acc: 83.22833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.47678 | Test accuracy: 83.34%\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Train Loss: 0.45479 | Train Acc: 84.20333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.55112 | Test accuracy: 81.43%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "\n",
      "Train Loss: 1.06544 | Train Acc: 62.10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:16,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.96374 | Test accuracy: 64.34%\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Train Loss: 0.78936 | Train Acc: 71.28333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.50098 | Test accuracy: 82.42%\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Train Loss: 0.46646 | Train Acc: 83.56000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.48469 | Test accuracy: 82.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed(42) \n",
    "torch.manual_seed(42)\n",
    "model_0 = FashionMNISTModelV0(784, 10, len(train_data.classes)).to(device)\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)   \n",
    "model_1 = FashionMNISTModelV1(784, 10, len(train_data.classes)).to(device)\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_0, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )\n",
    "\n",
    "train_loop(\n",
    "    epochs = 3, \n",
    "    model = model_1, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_1.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FashionMNISTModelV0', 'model_loss': 0.5511156320571899, 'model_acc': 81.4297124600639}\n",
      "{'model_name': 'FashionMNISTModelV1', 'model_loss': 0.48469090461730957, 'model_acc': 82.59784345047923}\n",
      "{'model_name': 'FashionMNISTModelV2', 'model_loss': 0.3342837989330292, 'model_acc': 87.74960063897764}\n"
     ]
    }
   ],
   "source": [
    "model_0_results = eval_model(\n",
    "    model = model_0,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")\n",
    "model_1_results = eval_model(\n",
    "    model = model_1,\n",
    "    data_loader = test_dataloader,\n",
    "    loss_fn = loss_fn,\n",
    "    accuracy_fn = accuracy_fn, \n",
    "    device = device \n",
    ")\n",
    "print(model_0_results)\n",
    "print(model_1_results)\n",
    "print(model_2_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "\n",
      "Train Loss: 0.26853 | Train Acc: 90.20167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:09<00:38,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.29770 | Test accuracy: 89.45%\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Train Loss: 0.26140 | Train Acc: 90.54500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:18<00:28,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.28215 | Test accuracy: 89.48%\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Train Loss: 0.25634 | Train Acc: 90.67333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:27<00:18,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30248 | Test accuracy: 89.25%\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Train Loss: 0.25073 | Train Acc: 90.81667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:36<00:09,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.28479 | Test accuracy: 89.79%\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Train Loss: 0.24720 | Train Acc: 90.87000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32323 | Test accuracy: 88.09%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(\n",
    "    epochs = 5, \n",
    "    model = model_2, \n",
    "    train_dataloader = train_dataloader, \n",
    "    test_dataloader = test_dataloader, \n",
    "    optimizer = torch.optim.SGD(params=model_2.parameters(), lr = 0.1), \n",
    "    loss_fn = loss_fn, \n",
    "    accuracy_fn = accuracy_fn,  \n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
